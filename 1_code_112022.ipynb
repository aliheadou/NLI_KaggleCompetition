{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le lien kernel pour ce projet est disponible à [ici](https://www.kaggle.com/code/alihigo/nli-xlm-roberta).\n",
    "\n",
    "## Le repo github est disponible [ici](https://github.com/aliheadou/NLI_KaggleCompetition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:36.350020Z",
     "iopub.status.busy": "2022-11-05T15:18:36.349423Z",
     "iopub.status.idle": "2022-11-05T15:18:37.117858Z",
     "shell.execute_reply": "2022-11-05T15:18:37.116401Z",
     "shell.execute_reply.started": "2022-11-05T15:18:36.349982Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:37.120157Z",
     "iopub.status.busy": "2022-11-05T15:18:37.119709Z",
     "iopub.status.idle": "2022-11-05T15:18:38.072980Z",
     "shell.execute_reply": "2022-11-05T15:18:38.072065Z",
     "shell.execute_reply.started": "2022-11-05T15:18:37.120112Z"
    }
   },
   "outputs": [],
   "source": [
    "%ls /kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:38.076500Z",
     "iopub.status.busy": "2022-11-05T15:18:38.076227Z",
     "iopub.status.idle": "2022-11-05T15:18:38.245225Z",
     "shell.execute_reply": "2022-11-05T15:18:38.244515Z",
     "shell.execute_reply.started": "2022-11-05T15:18:38.076470Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\n",
    "test_data  = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:38.247567Z",
     "iopub.status.busy": "2022-11-05T15:18:38.247311Z",
     "iopub.status.idle": "2022-11-05T15:18:38.268715Z",
     "shell.execute_reply": "2022-11-05T15:18:38.267905Z",
     "shell.execute_reply.started": "2022-11-05T15:18:38.247533Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:38.270323Z",
     "iopub.status.busy": "2022-11-05T15:18:38.269956Z",
     "iopub.status.idle": "2022-11-05T15:18:38.518562Z",
     "shell.execute_reply": "2022-11-05T15:18:38.517844Z",
     "shell.execute_reply.started": "2022-11-05T15:18:38.270272Z"
    }
   },
   "outputs": [],
   "source": [
    "labels, frequencies = np.unique(train_data.language.values, return_counts = True)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:38.519971Z",
     "iopub.status.busy": "2022-11-05T15:18:38.519688Z",
     "iopub.status.idle": "2022-11-05T15:18:38.741942Z",
     "shell.execute_reply": "2022-11-05T15:18:38.741267Z",
     "shell.execute_reply.started": "2022-11-05T15:18:38.519939Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = train_data.label.value_counts()\n",
    "plt.figure(figsize = (10,5))\n",
    "labels.plot.bar()\n",
    "plt.title(\"Number of items in each category\")\n",
    "plt.ylabel(\"Number (item)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:38.743619Z",
     "iopub.status.busy": "2022-11-05T15:18:38.743362Z",
     "iopub.status.idle": "2022-11-05T15:18:39.185163Z",
     "shell.execute_reply": "2022-11-05T15:18:39.184484Z",
     "shell.execute_reply.started": "2022-11-05T15:18:38.743578Z"
    }
   },
   "outputs": [],
   "source": [
    "## Comparing length of sentences in train_set\n",
    "hypo_len = train_data['hypothesis'].apply(len)\n",
    "prem_len = train_data['premise'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(hypo_len, bins=50, label=\"hypothesis length in train set\", alpha=0.5)\n",
    "plt.hist(prem_len, bins=50, label=\"premise length in train set\", alpha=0.5)\n",
    "plt.title(\"Length Comparison\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:39.186818Z",
     "iopub.status.busy": "2022-11-05T15:18:39.186557Z",
     "iopub.status.idle": "2022-11-05T15:18:53.588712Z",
     "shell.execute_reply": "2022-11-05T15:18:53.587810Z",
     "shell.execute_reply.started": "2022-11-05T15:18:39.186786Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:53.590695Z",
     "iopub.status.busy": "2022-11-05T15:18:53.590390Z",
     "iopub.status.idle": "2022-11-05T15:18:57.840401Z",
     "shell.execute_reply": "2022-11-05T15:18:57.839606Z",
     "shell.execute_reply.started": "2022-11-05T15:18:53.590656Z"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# SKLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:57.843797Z",
     "iopub.status.busy": "2022-11-05T15:18:57.843530Z",
     "iopub.status.idle": "2022-11-05T15:18:57.850305Z",
     "shell.execute_reply": "2022-11-05T15:18:57.849573Z",
     "shell.execute_reply.started": "2022-11-05T15:18:57.843764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Troncate Premises & Hypothesis sequences at max_len\n",
    "max_len=64\n",
    "\n",
    "# Loading Data Into TensorFlow Dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:57.853865Z",
     "iopub.status.busy": "2022-11-05T15:18:57.853650Z",
     "iopub.status.idle": "2022-11-05T15:18:57.862947Z",
     "shell.execute_reply": "2022-11-05T15:18:57.862085Z",
     "shell.execute_reply.started": "2022-11-05T15:18:57.853836Z"
    }
   },
   "outputs": [],
   "source": [
    "def troncate_sentence(sent, seq_len=max_len):\n",
    "    \"\"\"\" Return troncated sentence up to seq_len \"\"\"\n",
    "    try:\n",
    "        sent = sent.split()\n",
    "        sent = sent[:seq_len]\n",
    "        return \" \".join(sent)\n",
    "    except:\n",
    "        return sent\n",
    "\n",
    "def generate_tokens(df, tokenizer, seq_len=2*max_len):\n",
    "    \"\"\"\" Return list of token input_ids for a given dataframe\"\"\"\n",
    "    input_ids = []\n",
    "    input_masks = []\n",
    "    \n",
    "    for i, text in tqdm(enumerate(df.values.tolist()), total=len(df)):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=seq_len, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            # return_tensors='tf'\n",
    "        )\n",
    "    \n",
    "        input_ids.append(tokenized_text['input_ids'])\n",
    "        input_masks.append(tokenized_text['attention_mask'])\n",
    "    return input_ids, input_masks\n",
    "\n",
    "def get_body_encoding(hypothesis, premises, tokenizer):\n",
    "    \"\"\"\" Return encoded body from hyp and prem  \"\"\"\n",
    "    body = hypothesis.apply(troncate_sentence) + \"[SEP]\" + premises.apply(troncate_sentence)\n",
    "    return generate_tokens(body, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On applique une des variantes du modèle pré-entraîné multilingue `XLMRoberta` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:18:57.864968Z",
     "iopub.status.busy": "2022-11-05T15:18:57.864377Z",
     "iopub.status.idle": "2022-11-05T15:19:08.557596Z",
     "shell.execute_reply": "2022-11-05T15:19:08.556802Z",
     "shell.execute_reply.started": "2022-11-05T15:18:57.864931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
    "\n",
    "# Transformer Model Name\n",
    "transformer_model = 'joeddav/xlm-roberta-large-xnli' #'jplu/tf-xlm-roberta-large'\n",
    "\n",
    "# Define Tokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:19:08.559262Z",
     "iopub.status.busy": "2022-11-05T15:19:08.558994Z",
     "iopub.status.idle": "2022-11-05T15:19:08.563722Z",
     "shell.execute_reply": "2022-11-05T15:19:08.562925Z",
     "shell.execute_reply.started": "2022-11-05T15:19:08.559224Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(generate_tokens(pd.Series([\"The rules developed in the interim\"]), tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:19:08.565703Z",
     "iopub.status.busy": "2022-11-05T15:19:08.565389Z",
     "iopub.status.idle": "2022-11-05T15:22:42.624403Z",
     "shell.execute_reply": "2022-11-05T15:22:42.623620Z",
     "shell.execute_reply.started": "2022-11-05T15:19:08.565669Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pretrained Transformer Model\n",
    "transformer_encoder = TFXLMRobertaModel.from_pretrained(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:23:20.476044Z",
     "iopub.status.busy": "2022-11-05T15:23:20.475767Z",
     "iopub.status.idle": "2022-11-05T15:23:20.485102Z",
     "shell.execute_reply": "2022-11-05T15:23:20.482664Z",
     "shell.execute_reply.started": "2022-11-05T15:23:20.476016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build model function\n",
    "def build_model(transformer, final_len=2*max_len, learnin_rate=2e-6):\n",
    "    # Input\n",
    "    # input_layer = tf.keras.layers.Input(shape=(final_len,), dtype=tf.int32, name=\"input_layer\")\n",
    "    input_ids = tf.keras.layers.Input(shape=(final_len,), name='input_ids', dtype='int32')\n",
    "    input_masks = tf.keras.layers.Input(shape=(final_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "    # Sequence output\n",
    "    sequence_output = transformer(input_ids, attention_mask=input_masks)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    cls_token = tf.keras.layers.Dropout(0.3)(cls_token)\n",
    "    cls_token = tf.keras.layers.Dense(64, activation='relu')(cls_token)\n",
    "    # Output Layers\n",
    "    output_layer = tf.keras.layers.Dense(3, activation='softmax')(cls_token)\n",
    "    # Model graph\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, input_masks], outputs=output_layer)\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learnin_rate), \n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:22:42.637242Z",
     "iopub.status.busy": "2022-11-05T15:22:42.636351Z",
     "iopub.status.idle": "2022-11-05T15:22:54.458613Z",
     "shell.execute_reply": "2022-11-05T15:22:54.457793Z",
     "shell.execute_reply.started": "2022-11-05T15:22:42.637207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into Training (90%) & Validation (10%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data[['premise','hypothesis']], \n",
    "    train_data.label.values, \n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "# Prepare inputs\n",
    "# Training set\n",
    "train_input_ids, train_attn_masks = get_body_encoding(\n",
    "    x_train['hypothesis'],\n",
    "    x_train['premise'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_input_ids, train_attn_masks, y_train)).repeat().shuffle(2048).batch(batch_size).prefetch(AUTO)\n",
    "# Validation set\n",
    "valid_input_ids, valid_attn_masks = get_body_encoding(\n",
    "    x_val['hypothesis'],\n",
    "    x_val['premise'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((valid_input_ids, valid_attn_masks, y_val)).batch(batch_size).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:22:54.460486Z",
     "iopub.status.busy": "2022-11-05T15:22:54.460190Z",
     "iopub.status.idle": "2022-11-05T15:22:54.542927Z",
     "shell.execute_reply": "2022-11-05T15:22:54.542049Z",
     "shell.execute_reply.started": "2022-11-05T15:22:54.460450Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# then we use the dataset map method to apply this transformation\n",
    "train_ds = train_ds.map(map_func)\n",
    "val_ds = val_ds.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:23:26.204703Z",
     "iopub.status.busy": "2022-11-05T15:23:26.204423Z",
     "iopub.status.idle": "2022-11-05T15:23:29.274724Z",
     "shell.execute_reply": "2022-11-05T15:23:29.273965Z",
     "shell.execute_reply.started": "2022-11-05T15:23:26.204674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Application to xlm_roberta\n",
    "xlm_model = build_model(transformer = transformer_encoder)\n",
    "# Model Summary\n",
    "xlm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:23:30.519209Z",
     "iopub.status.busy": "2022-11-05T15:23:30.518546Z",
     "iopub.status.idle": "2022-11-05T15:23:31.528230Z",
     "shell.execute_reply": "2022-11-05T15:23:31.527403Z",
     "shell.execute_reply.started": "2022-11-05T15:23:30.519170Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(xlm_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:23:37.609710Z",
     "iopub.status.busy": "2022-11-05T15:23:37.609416Z",
     "iopub.status.idle": "2022-11-05T15:46:54.948452Z",
     "shell.execute_reply": "2022-11-05T15:46:54.947632Z",
     "shell.execute_reply.started": "2022-11-05T15:23:37.609675Z"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# On-the-fly data augmentation\n",
    "n_steps = len(train_data) // batch_size \n",
    "\n",
    "# Train the Model\n",
    "hist_xlm = xlm_model.fit(\n",
    "    train_ds, \n",
    "    validation_data = val_ds,\n",
    "    epochs = 10,\n",
    "    steps_per_epoch = n_steps,\n",
    "    callbacks=[stop_early],\n",
    "#    batch_size = 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:47:33.416958Z",
     "iopub.status.busy": "2022-11-05T15:47:33.416317Z",
     "iopub.status.idle": "2022-11-05T15:47:33.826713Z",
     "shell.execute_reply": "2022-11-05T15:47:33.825988Z",
     "shell.execute_reply.started": "2022-11-05T15:47:33.416920Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_xlm.history).loc[:, [\"accuracy\", \"val_accuracy\"]].plot()\n",
    "pd.DataFrame(hist_xlm.history).loc[:, [\"loss\", \"val_loss\"]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T15:47:39.131724Z",
     "iopub.status.busy": "2022-11-05T15:47:39.131139Z",
     "iopub.status.idle": "2022-11-05T15:48:01.638790Z",
     "shell.execute_reply": "2022-11-05T15:48:01.637979Z",
     "shell.execute_reply.started": "2022-11-05T15:47:39.131685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate on Validation Set\n",
    "xlm_model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.966659Z",
     "iopub.status.idle": "2022-11-05T15:23:01.967105Z",
     "shell.execute_reply": "2022-11-05T15:23:01.966899Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.966877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted labels\n",
    "y_pred = xlm_model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Construction of cm\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "c = sns.heatmap(cm, annot=True, fmt='g', cbar=False)\n",
    "c.set_xlabel('Predicted')\n",
    "c.set_ylabel('Truth')\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.968529Z",
     "iopub.status.idle": "2022-11-05T15:23:01.969016Z",
     "shell.execute_reply": "2022-11-05T15:23:01.968805Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.968782Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(\n",
    "    y_val,\n",
    "    y_pred,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.970395Z",
     "iopub.status.idle": "2022-11-05T15:23:01.970910Z",
     "shell.execute_reply": "2022-11-05T15:23:01.970699Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.970676Z"
    }
   },
   "outputs": [],
   "source": [
    "# del test_ds\n",
    "def map_func_test(input_ids, masks):\n",
    "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.973010Z",
     "iopub.status.idle": "2022-11-05T15:23:01.973579Z",
     "shell.execute_reply": "2022-11-05T15:23:01.973370Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.973348Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input_ids, test_attn_masks = get_body_encoding(\n",
    "    test_data['hypothesis'],\n",
    "    test_data['premise'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_input_ids, test_attn_masks)).batch(batch_size).prefetch(AUTO)\n",
    "test_ds = test_ds.map(map_func_test)\n",
    "#test_ds = (tf.data.Dataset.from_tensor_slices((test_encode)).batch(batch_size).prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.975026Z",
     "iopub.status.idle": "2022-11-05T15:23:01.976733Z",
     "shell.execute_reply": "2022-11-05T15:23:01.976495Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.976471Z"
    }
   },
   "outputs": [],
   "source": [
    "submissions = xlm_model.predict(test_ds, verbose=0)\n",
    "y_subm = np.argmax(submissions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0 == entailment                        \n",
    "    1 == neutral                                  \n",
    "    2 == contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.977976Z",
     "iopub.status.idle": "2022-11-05T15:23:01.978932Z",
     "shell.execute_reply": "2022-11-05T15:23:01.978729Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.978706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Submission \n",
    "sample_subm = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/sample_submission.csv')\n",
    "sample_subm['prediction'] = y_subm\n",
    "sample_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-05T15:23:01.980028Z",
     "iopub.status.idle": "2022-11-05T15:23:01.980972Z",
     "shell.execute_reply": "2022-11-05T15:23:01.980755Z",
     "shell.execute_reply.started": "2022-11-05T15:23:01.980714Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_subm.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le notebook ci-dessus est inspiré des kernels suivant:\n",
    "    https://www.kaggle.com/code/antoinegoubert/xlmroberta-curriculum-learning-xnli-data-aug/notebook?scriptVersionId=106747526\n",
    "    https://www.kaggle.com/code/francescoliveras/contradictory-nn-tpu-en-es/notebook?scriptVersionId=107715163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
